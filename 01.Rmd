---
title: "cs412_assignment1"
output:
  pdf_document: default
  html_document: default
---

# 1.
```{r}
col_names = c("id","midterm","final")
df = read.csv("data.online.scores.txt",header = FALSE,sep = "\t",
              col.names = col_names)
```

## a.
### max() function displays the maximum number in data
```{r}
max(df['midterm'])
```
### min() function displays the minimum number in data
```{r}
min(df['midterm'])
```

##b
```{r}
x = df[['midterm']]
quantile(x)
```
```{r}'
First quantile is 68, median is 77, third quantile is 87.
```

##c
### mean() is calculating the average
```{r}
m = mean(x)
m
```

##d used table() to make a table of the number of times that each data point appear in the whole dataset, and subset the largest data point
```{r}
t = table(x)
t[t==max(t)]
```
```{r}'
The mode are 77 and 83.
```

##e var() is calling sample variance
```{r}
variance = var(x)
round(variance,3)
```
```{r}'
The variance is 173.279 based on the formula
```
  $$s = 1/(n-1)\sum_{i=1}^n(x_i-\bar x)^2$$

# 2.

## a
```{r}
var_before = var(x)
x_norm = (x-m)/sqrt(var_before)
var_after = var(x_norm)
round(var_before,3)
round(var_after,3)
```
```{r}'
After normalization, the variance is one compared to the variance before normalization is 173.2791.
```
The equation of normalization is
$$z = \frac{x - \bar{x}}{\sqrt{\sigma^2}}$$

## b
```{r}
round((90-m)/sqrt(var_before),3)
```

## c
```{r}
x2 = df[["final"]]
correlation = cor(x,x2)
round(correlation,3)
```
The formula of Pearson's correlation coefficient is
$$ r_{x,y} = \frac{cov(X,Y)} {\sigma_x \sigma_y} = \frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum_{i=1}^n(x_i-\bar x)^2)}\sqrt{\sum_{i=1}^n(y_i-\bar y)^2)}}  $$
            
            
## d
```{r}
covariance = cov(x,x2)
round(covariance,3)
```
The formula of covariance is 
$$ cov_{x,y} = \frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{n-1} $$
# 3

## a
```{r}
round(58/(120+2+58),3)
```
The formula of Jaccard coefficient is
$$ sim_{Jaccard}(i,j) = \frac{q}{q+r+s}$$
## b
```{r}
df1 = read.table("data.libraries.inventories.txt",sep = "\t",header = TRUE)
df1$library = NULL
rownames(df1) = c('Citadel','Castle')
```

### 1. h = 1
dist() function using the specified distance measure to calculates and returns the distance matrix
```{r}
dist(df1,method = "manhattan")
```


### 2. h = 2
```{r}
round(dist(df1,method = "euclidean"),3)
```

### 3. h = $-\infty$
```{r}
dist(df1,method = "maximum")
```

## c
```{r}
cml = df1[1,]
cbl = df1[2,]
cosine = sum(cml*cbl)/(sqrt(sum(cml^2))*sqrt(sum(cbl^2)))
round(cosine,3)
```
The formula of cosine similarity is 
$$cos(d_1,d_2) = \frac{d_1 * d_2}{||d_1|| * ||d_2||} $$
## d
```{r}
epsi = 0.0001
require(flexmix)
cml1 = as.numeric(as.vector(df1[1,]))
cbl1 = as.numeric(as.vector(df1[2,]))
y = cbind(cml1,cbl1)
kl = KLdiv(y)
round(kl[1,2],3)
```

Or by formula
  $$D_{KL}(p(x)||q(x)) = \sum p(x)ln\frac{p(x)}{q(x)}$$
```{r}
c1 = sum(cml1)
c2 = sum(cbl1)
round(sum(cml1/c1*log((cml1/c1/(cbl1/c2)))),3)
```

# 4.
By the formula of chi-square correlation
    $$ \chi ^2 = \sum_{i=1}^n\frac{(O_i-E_i)^2}{E_i}$$ 
```{r}
beer = matrix(c(150, 40, 15, 3300),ncol = 2,byrow = TRUE)
beer
row.names(beer) = c("buy beer","do not buy beer")
colnames(beer) = c("buy diaper","do not buy diaper")
sums = 150+40+15+3300
E_b_d = (150+40)*(150+15)/sums
E_b_nd = (150+40)*(40+3300)/sums
E_nb_d = (15 + 3300)*(150+15)/sums
E_nb_nd = (15 + 3300)*(40+3300)/sums
chi = (150-E_b_d)^2/E_b_d + (40-E_b_nd)^2/E_b_nd +
  (15 - E_nb_d)^2/E_nb_d + (3300-E_nb_nd)^2/E_nb_nd
chi
```
```{r}'
Since value of chi-square test is large, we reject the hypothesis that
the two variables are independent to each other.
```


